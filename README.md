# Hyperparameter Optimization: Grid and Random Search



This project focuses on tuning hyperparameters for a small CNN model on the MNIST dataset using **Grid Search** and **Random Search** techniques. The primary goal is to explore the effects of hyperparameters like learning rate, batch size, and dropout rate on model performance.

## Project Overview
- **Model**: Convolutional Neural Network (CNN) for digit classification.
- **Dataset**: MNIST (handwritten digits).
- **Hyperparameters Tuned**:
  - Learning rate
  - Batch size
  - Dropout rate

## Key Objectives
- Compare the performance of Grid Search and Random Search.
- Analyze model accuracy and generalization with varying hyperparameters.
- Visualize and document results for a better understanding of optimal configurations.

## Results
Detailed visualizations and metrics are included for each search method to illustrate performance trends.

---

*If you want me to cooperate in any project, you can contact me via email: mohammed.khalil.mah@gmail.com*
